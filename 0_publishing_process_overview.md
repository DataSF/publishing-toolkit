# Publishing Process Overview

## Introduction

DataSF seeks to empower use of the City's data. Making open data available is not the singular way we do this, but it is one way we drive toward that mission. Over time, we seek to increase the accessibility, discoverability, and understanding of City data.

We've designed the publishing process to balance our vision with operational realities. Specifically, there are hundreds of data systems across more than 50 departments.

We cannot apply a monolithic approach to data publishing. Instead, we apply patterns and best practices suited to the context of the data being published. This involves an appropriate mix of people, technology and process within an always learning organization.

We've designed our processes and toolkit to:

1. Decrease overhead for DataSF staff and City publishers
2. Provide the necessary information at the appropriate time
3. Leverage automation and work flow tools where possible
4. Maintain DataSF team transparency and collaboration on the process

## Processes

The publishing process is a set of sub-processes linked together through decision points. The sub processes are:

**Submission and Intake.** The department publisher submits information to DataSF through an intake form. DataSF staff use the information provided to inform the downstream processes.

**Inventory Update.** Some reconciliation between the dataset inventory and the submission has to happen. This includes updating fields in the inventory or adding a record to the inventory if that dataset is absent.

**Manual Publishing.** If the dataset is more appropriate to load manually, DataSF staff provide documentation and training as needed so that the data publisher can manually load and update data as needed.

**ETL Specification.** If the dataset is appropriate for automation, DataSF staff work with the data publisher to establish the best method for extraction and the desired output. This could include transformations and other automation services.

**ETL Development.** DataSF staff implement automation for the dataset according to the specifications.

**Release Toolkit Review.** For protected or sensitive data

